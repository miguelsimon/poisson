{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import autograd_objective\n",
    "from poisson_id_link_model import Problem, Sim, fit, XObjEstimator\n",
    "from evaluate_errors import Evaluate, NullaryEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We're modelling particle counts at $k$ detectors, caused by an event in a space X, discretized as $X^m$.\n",
    "\n",
    "We assume that we can model a count at a detector $y_i$ as a Poisson distribution dependent on an event vector $x^m$,\n",
    "\n",
    "$$\n",
    "y_i \\sim Poisson(\\lambda_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_i = \\alpha_i \\cdot x^m + \\beta_i = \\theta_i \\cdot x^m\n",
    "$$\n",
    "\n",
    "where:\n",
    "* the $x^m$ vectors are sparse; they correspond to a point event\n",
    "* the structure of $\\theta_i$ is not clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, say we've got 3 detectors, and we've discretized the space where decomposition events happen into $m=4$ cells.\n",
    "\n",
    "The Poisson means $\\lambda_i$ are given by\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix} \n",
    "\\lambda_0 \\\\\n",
    "\\lambda_1 \\\\\n",
    "\\lambda_2 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "=\n",
    "\\left[\n",
    "\\begin{matrix} \n",
    "\\alpha_{00} & \\alpha_{01} & \\alpha_{02} & \\alpha_{03} & \\beta_0 \\\\\n",
    "\\alpha_{10} & \\alpha_{11} & \\alpha_{12} & \\alpha_{13} & \\beta_1 \\\\\n",
    "\\alpha_{20} & \\alpha_{21} & \\alpha_{22} & \\alpha_{23} & \\beta_2 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\cdot\n",
    "\\left[\n",
    "\\begin{matrix} \n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "1 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems intuitive to me; an event in a given cell causes Poisson-distributed counts in a given detector; the dark count rate is taken care of by $\\beta$; rates are linear in the events.\n",
    "\n",
    "So we have 2 problems.\n",
    "\n",
    "### Estimate the parameter vector $\\theta$ given training data $(x, y)$\n",
    "\n",
    "We have training tuples (presumably from the geant4 simulation) and we use them to estimate the $\\theta$ coefficients.\n",
    "\n",
    "### Given $\\theta$ and detector responses $y$, find the most plausible event vector $x^m$\n",
    "\n",
    "As I understand it, in each time slice we're assuming either 0 or 1 decomposition events happen.\n",
    "\n",
    "If our event space has been discretized into $m$ cells, we have $m + 1$ alternative hypotheses $H = \\{\\overrightarrow{0}, \\overrightarrow{e_1}, \\overrightarrow{e_2}, \\ldots, \\overrightarrow{e_m}\\}$ for each time slice that can explain the detector measurements: the unit vectors in $R^m$ and the $0^m$ vector.\n",
    "\n",
    "So if we have a function proportional to the likelihood $l(y \\mid \\theta, x^m)$ implied by our Poisson model, we're looking for\n",
    "\n",
    "$$\n",
    "\\underset{x^m \\in H}{\\text{argmax}} \\, l(y \\mid \\theta, x^m)\n",
    "$$\n",
    "\n",
    "We get an easy $l$ function if we assume indepedence between detectors and simply multiply their likelihoods together.\n",
    "\n",
    "This is where the l1 penalty might come in useful as the $x^m$ vector is very sparse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem characterization\n",
    "\n",
    "Our problems are characterized by:\n",
    "* the number of detectors $y\\_dim$\n",
    "* the number of discretized space voxels $x\\_dim$\n",
    "\n",
    "so let's come up with a dummy problem and try to recover $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29000000e-04 4.80000001e-05 3.09400000e-03]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([\n",
    "    [1.0, 0.5, 0.1, 0.1, 0.01],\n",
    "    [0.5, 0.1, 1.0, 0.1, 0.01],\n",
    "    [0.1, 1.0, 0.5, 0.1, 0.3], # this one's dcr is high\n",
    "])\n",
    "sim = Sim(theta)\n",
    "xs, ys, eys = [], [], []\n",
    "for i in range(100000):\n",
    "    x, y = sim.sample()\n",
    "    e_y = sim.obj.Ey_given_x(sim.theta, x)\n",
    "    ys.append(y)\n",
    "    eys.append(e_y)\n",
    "    \n",
    "# quick sanity check\n",
    "print(np.mean(ys, axis = 0) - np.mean(eys, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of concept solver:\n",
    "* I'm being really braindead about it, not taking advantage of the sparsity of $x$ to get a quadratic speed up and give the solver an easier time\n",
    "* I'm using the scipy [trust-constr solver](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-trustconstr.html) because we have a nonnegativity constraint\n",
    "* I'm also using [autograd](https://github.com/HIPS/autograd) because it's super easy to get the gradient and I can use the built-in hessian vector product to give the solver second-order information (not that I know if it matters)\n",
    "\n",
    "There must be a specialized solver for this somewhere, maybe in [cvxopt](https://cvxopt.org/) or in [The Bible](https://web.stanford.edu/~boyd/cvxbook/), but I try not to look at the Boyd & Vandenberghe book for too long because it makes my brain hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs_100, train_ys_100 = sim.sample_n(100)\n",
    "obj = autograd_objective.ThetaObjective(train_xs_100, train_ys_100)\n",
    "theta_100, _sol = fit(obj)\n",
    "frobenius_100 = np.linalg.norm(theta - theta_100, ord=\"fro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it more samples and see if the frobenius norm $\\| \\theta - \\hat{\\theta} \\|_{\\rm F}$ goes down as expected as the number of samples goes up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius 100: 0.46559827333064924 1000: 0.3083645471813448\n"
     ]
    }
   ],
   "source": [
    "train_xs_1000, train_ys_1000 = sim.sample_n(1000)\n",
    "obj = autograd_objective.ThetaObjective(train_xs_1000, train_ys_1000)\n",
    "theta_1000, _sol = fit(obj)\n",
    "frobenius_1000 = np.linalg.norm(theta - theta_1000, ord=\"fro\")\n",
    "print('frobenius 100: {0} 1000: {1}'.format(frobenius_100, frobenius_1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding x\n",
    "\n",
    "Engineering beats cleverness, so let's start with a framework that lets us easily evaluate our estimators.\n",
    "\n",
    "We can start from a baseline *nullary* estimator; this simply draws samples from the marginal x distribution; it's simply a random guess consistent with the marginal x distribution.\n",
    "\n",
    "If we can't beat this, we're screwed.\n",
    "\n",
    "We can start by comparing it to our X estimator *given perfect knowledge of theta*, and our X estimator given theta_100, that is, theta trained on 100 samples.\n",
    "\n",
    "Results are... *interesting*:\n",
    "\n",
    "* median errors of both theta and theta_100 are lower than the nullary estimator which is expected\n",
    "* theta_100 has more outliers than theta, which is expected\n",
    "* theta is really bad at some points and I'm getting `invalid values encountered in log` errors, which means I probably didn't **completely** screw up the X objective but it's unstable, maybe because I chose a physically implausible theta matrix in the first place, maybe it's lacking regularization, or I **did** completeley screw it up and the better median is due to other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelsimon/poisson/env/lib/python3.7/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_xs, test_ys = sim.sample_n(100)\n",
    "nullary_estimator = NullaryEstimator(sim)\n",
    "theta_100_estimator = XObjEstimator('theta_100', theta_100)\n",
    "theta_estimator = XObjEstimator('theta', theta)\n",
    "\n",
    "evaluator = Evaluate([nullary_estimator, theta_100_estimator, theta_estimator], test_xs, test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD5CAYAAAAOXX+6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAP0ElEQVR4nO3df4zk9V3H8dfLucWFgnCEjbH8cKnBOjBVkLGWcn90aWNpRYkWDRur4k1yiY1jUSNHM0bu/ljjxabBLlRzsFdMxSEB+wc2NRTjYJ3GALvlGvZYMSc/yiHVRa6F1B4Mx9s/ZvZ2b7N3+73d+d58Zub5SDaZ+Xy/89333Xc/r/3u5/v5fr+OCAEA0vVDvS4AAHByBDUAJI6gBoDEEdQAkDiCGgAStyWPjV5wwQUxPj6ex6YBYCDNzc29GhFjay3LJajHx8c1Ozubx6YBYCDZfvFEyxj6AIDEEdQAkDiCGgASR1ADQOIIagBIHEGNoVCv11UqlVQoFFQqlVSv13tdEpBZLtPzgJTU63XVajXNzMxo27ZtajabqlQqkqTJyckeVwesz3nc5rRcLgfzqJGKUqmk6elpTUxMHGtrNBqqVquan5/vYWXAMttzEVFecxlBjUFXKBR05MgRjYyMHGtrtVoaHR3V0aNHe1gZsOxkQc0YNQZesVhUs9k8rq3ZbKpYLPaoIuDUENQYeLVaTZVKRY1GQ61WS41GQ5VKRbVardelAZlwMhEDb+mEYbVa1cLCgorFoqampjiRiL7BGDUAJIAxagDoYwQ1ACSOoAaAxBHUAJA4ghoAEkdQA0DiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxBDUAJI6gBoDEEdQAkDiCGgASR1ADQOIyBbXtP7B9wPa87brt0bwLAwC0rRvUti+U9PuSyhFRklSQdHPehQEA2rIOfWyRdKbtLZLOkvRf+ZUEAFhp3aCOiJclfVbStyW9Iul7EfG1vAsDALRlGfrYKulGSZdKerekd9n+5Brr7bA9a3t2cXGx+5UCwJDKMvTxEUnPR8RiRLQkfVnSB1evFBF7I6IcEeWxsbFu1wkAQytLUH9b0gdsn2Xbkj4saSHfsgAAS7KMUT8u6SFJ35T0dOcze3OuCwDQsSXLShFxh6Q7cq4FALAGrkwEgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxBDUAJI6gBoDEEdQAkDiCGgASR1ADQOIIagBIHEENAIkjqAEgcQQ1ACSOoAaAxBHUAJA4ghoAEkdQA0DiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxBDUAJI6gxlCo1+sqlUoqFAoqlUqq1+u9LgnIbEuWlWyfJ+leSSVJIWl7RPxbnoUB3VKv11Wr1TQzM6Nt27ap2WyqUqlIkiYnJ3tcHbA+R8T6K9l/I+lfI+Je22dIOisivnui9cvlcszOznaxTGDjSqWSpqenNTExcayt0WioWq1qfn6+h5UBy2zPRUR5zWXrBbXtcyXtl/SeyJLqIqiRlkKhoCNHjmhkZORYW6vV0ujoqI4ePdrDyoBlJwvqLGPUl0palPRF20/Zvtf2u9b4Jjtsz9qeXVxc3GTJQPcUi0U1m83j2prNporFYo8qAk5NlqDeIulnJf1VRFwl6fuSbl+9UkTsjYhyRJTHxsa6XCawcbVaTZVKRY1GQ61WS41GQ5VKRbVardelAZlkOZl4SNKhiHi88/4hrRHUQKqWThhWq1UtLCyoWCxqamqKE4noG+sGdUR8x/ZLtt8bEc9K+rCkZ/IvDeieyclJghl9K9P0PElVSfd3Znw8J+l38isJALBSpqCOiP2S1jwbCQDIF1cmAkDiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxBDUAJI6gBoDEEdQAkDiCGgASR1ADQOIIagBIHEENAIkjqAEgcQQ1ACSOoAaAxBHUGAr1el2lUkmFQkGlUkn1er3XJQGZbel1AUDe6vW6arWaZmZmtG3bNjWbTVUqFUnS5ORkj6sD1ueI6PpGy+VyzM7Odn27wEaUSiVNT09rYmLiWFuj0VC1WtX8/HwPKwOW2Z6LiPKaywhqDLpCoaAjR45oZGTkWFur1dLo6KiOHj3aw8qAZScLasaoMfCKxaKazeZxbc1mU8VisUcVAaeGoMbAq9VqqlQqajQaarVaajQaqlQqqtVqvS4NyISTiRh4SycMq9WqFhYWVCwWNTU1xYlE9A3GqAEgAYxRA0AfI6gBIHEENQAkLnNQ2y7Yfsr2V/IsCABwvFM5ov60pIW8CgEArC1TUNu+SNIvSro333IAAKtlPaK+U9Jtkt450Qq2d9ietT27uLjYleIAABmC2vYNkv4nIuZOtl5E7I2IckSUx8bGulYgAAy7LEfU10r6ZdsvSHpA0nW2/zbXqgAAx6wb1BHxmYi4KCLGJd0s6Z8j4pO5VwYAkMQ8agBI3indlCkiHpP0WC6VAADWxBE1ACSOoAaAxBHUAJI37E+R58EBAJLGU+R5cACAxA3LU+R5CjmAvjUsT5HnCS8A+laxWNTu3buPG6PevXv3UD1FnqAGkLSJiQnt2bNH27dv1xtvvKHt27drz549xw2FDDqCGkDSGo2Gdu7cqX379umcc87Rvn37tHPnTjUajV6XdtowRg0gaYxRc0QNIHHFYlHNZvO4tmazyRg1AKSiVqupUqmo0Wio1Wqp0WioUqmoVqv1urTThgteACRt6aKWarWqhYUFFYtFTU1NDc3FLhJj1ACQBMaoAaCPEdQAkDiCGkNh2O++hv7GyUQMPO6+hn7HyUQMvGG5+xr6G3fPw1Ablivb0N+Y9YGhxt3X0O8Iagw87r6GfkdQY+Bx9zX0O8aoMfAYo0Y/YIwaQ427r6HfEdQYeNx9Df2OC14w8Lj7GvodY9QYKLY3vY08+gSwnpONUXNEjYGyXsjaJojRdxijBoDEEdQAkDiCGgASR1ADQOLWDWrbF9tu2H7G9gHbnz4dhQEA2rLM+nhb0h9FxDdtnyNpzvajEfFMzrUBGCLdmFopDeb0ynWDOiJekfRK5/UbthckXSiJoAbQNVkCdlinV57SGLXtcUlXSXp8jWU7bM/anl1cXOxOdQCA7EFt+2xJfy/p1oh4ffXyiNgbEeWIKI+NjXWzRgAYapmC2vaI2iF9f0R8Od+SAAArZZn1YUkzkhYi4nP5lwQAWCnLEfW1kn5T0nW293e+Pp5zXQCAjiyzPpqSujNvBgBwyrgyEQASR1ADQOIIagBIHEENAIkjqAEgcQQ1ACSOZyauwh28AKSGoF6Fh6MCSA1DHwCQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxBDUAJG745lHvOndTH487fmTT22jX8b3Nb2PInH/++Tp8+PCmt7PZi5q2bt2q1157bdN1DJsU9l+/7ruhC2rvfr3nF6zYVuzqaQl96fDhwz3fd1L3rl4dNinsv37ddwx9AEDiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0AiSOoASBxQ3dTJgC90bU7T262hj5EUKNvpNDRj9WBU8adKzeOoEbfSKGjS/3b2dG/GKMGgMRlCmrb19t+1vZB27fnXRQAYNm6QW27IOluSR+TdLmkSduX510YAKAtyxH1+yUdjIjnIuItSQ9IujHfsgAAS7KcTLxQ0ksr3h+S9POrV7K9Q9IOSbrkkku6Ulxeev3ctK1bt/b0+/ezXu87if23Gb3ef/2677o26yMi9kraK0nlcrn3p+ZPIIVZA9gY9l1/Y/9tXJahj5clXbzi/UWdNgDAaZAlqJ+UdJntS22fIelmSQ/nWxYAYMm6Qx8R8bbt35P0iKSCpH0RcSD3ygAAkjKOUUfEVyV9NedaAABr4MpEAEgcQQ0AiSOoASBxBDUAJM55TEK3vSjpxa5vOA0XSHq110Vgw9h//W2Q99+PR8TYWgtyCepBZns2Isq9rgMbw/7rb8O6/xj6AIDEEdQAkDiC+tTt7XUB2BT2X38byv3HGDUAJI4jagBIHEENAIkjqNdh+0O2v9J5fYvtu3pdEzAIbJ9n+1Od18f62Sl8/hbb786nurQQ1Dmy3bUn6AyDXnZc279m+4Dtd2yXVy37jO2Dtp+1/dEV7dd32g7avn0j33fInSfpU5v4/C2SCOpBZHvc9oLtezod82u2z7T92FIHtX2B7RfW2c4v2X7c9lO2/8n2j3bad9n+ku1vSPqS7a/bvnLF55q2fybPf2Mf62XHnZf0q5K+vrLR9uVqPyzjCknXS/qC7YLtgqS7JX1M0uWSJjvrIrs/l/QTtvdL+gtJZ9t+yPa/277fnQcs2r7a9r/YnrP9iO0fs32TpLKk+23v7/ThP7X9pO1523uXPj8Ihi6oOy6TdHdEXCHpu5I+sYFtNCV9ICKuUvvJ7LetWHa5pI9ExKSkGbUDRLZ/UtJoRHxrE7UPsp513IhYiIhn11h0o6QHIuLNiHhe0kFJ7+98HYyI5yLiLbV/Bm7s6v/G4Ltd0n9GxJWS/ljSVZJuVbv/vEfStbZHJE1Luikirpa0T9JURDwkaVbSb0TElRHxA0l3RcTPRURJ0pmSbjj9/6R8DGtQPx8R+zuv5ySNb2AbF0l6xPbTav+QXbFi2cOdHxxJelDSDZ0fuO2S7ttQxcMhxY57oaSXVrw/1Gk7UTs27omIOBQR70jar3a/fK+kkqRHO7/A/0TtvreWic5fuU9Luk7H98m+NqxjqG+ueH1U7U78tpZ/cY1m2Ma0pM9FxMO2PyRp14pl3196ERH/Z/tRtY+2fl3S1Rsve+g8ERGHJKnTScfV/gtoqeNK7cfDvXKCz0/Yvk3SWZLOl3RA0j/kXDM2bnW/3CLJkg5ExDUn+6DtUUlfkFSOiJds71K2ftwXhvWIei0vaDlEb8qw/rlafhr7b6+z7r2SPi/pyYg4vKHqhtPJOu6Vna/3RcQvrP7gio57U0S8T9I92ljHfVnSxSveX9RpO1E7sntD0jnrrPOspDHb10iS7RHbS0fKKz+/tG9ftX22svXhvkFQL/uspN+1/ZTat1Jczy5JD9qe0zq3XYyIOUmvS/riZosccCl23Icl3Wz7h21fqvb5jSckPSnpMtuX2j5D7ROOD2/wewyliPhfSd+wPa/2OYm11nlL7X23x/a31B4S+WBn8X2S/rrz19abav8ynlf7QdxP5lv96cUl5KdBZ8rYY5J+qjP+hhOw/XeSflrSDyT9d0Tc0Gm/S9JsRNzXmUXzebX/qtki6c6IuMf2JyT9Weez10iqSZqU9B1J/yHpxYjYdYLv+ytqD2eNqT28sj8iPtpZVlP7/MLbkm6NiH/stH9c0p1qD7/si4ipLv93AJII6tzZ/i1JU5L+MCIe7HU9APoPQQ0AiRvWWR8YUrbvlnTtqua/jAjOHyBZHFEDQOKY9QEAiSOoASBxBDUAJI6gBoDE/T8FbjhyKvJZlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
